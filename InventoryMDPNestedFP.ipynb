{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEvjxBhV0kI/YFytSPkoXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nosadchiy/public/blob/main/InventoryMDPNestedFP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmzmTslkhkIJ",
        "outputId": "7e5187fe-9630-4ca3-ae0b-74048d2a60c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True        [K, h, b]: 5.0 0.5 2.0\n",
            "Estimation Results:\n",
            "  success: True\n",
            "  estimated [K, h, b]: [4.95986385 0.50891179 2.05483685]\n",
            "  negative log-likelihood: 1940.6778383591218\n",
            "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "###############################################################################\n",
        "# 1. Define the Inventory MDP Class\n",
        "###############################################################################\n",
        "\n",
        "class InventoryBackorderMDP:\n",
        "    \"\"\"\n",
        "    A single-product inventory model with backorders.\n",
        "\n",
        "    States (i): integer on-hand inventory (i >= 0) or negative for backorders.\n",
        "                We truncate to range [i_min, i_max].\n",
        "    Actions (Q): discrete order quantity (0..Q_max).\n",
        "\n",
        "    Demand: Poisson(lambda_) by default, but can be replaced with any pmf.\n",
        "    Costs:\n",
        "       - K * indicator(Q>0)   (fixed order cost)\n",
        "       - c * Q                (per-unit ordering cost)\n",
        "       - h * max(i', 0)       (holding cost on leftover inventory)\n",
        "       - b * max(-i', 0)      (backorder cost if i' < 0)\n",
        "    i' = i + Q - D is the next inventory level after demand.\n",
        "\n",
        "    This MDP is solved by value iteration with a discount factor beta.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 i_min=-5,       # smallest state we track (backorder limit)\n",
        "                 i_max=10,       # largest state we track\n",
        "                 Q_max=5,        # max order quantity\n",
        "                 lambda_=2.0,    # demand mean if using Poisson\n",
        "                 beta=0.95,      # discount factor\n",
        "                 K=5.0,          # fixed order cost\n",
        "                 c=1.0,          # per-unit ordering cost\n",
        "                 h=0.5,          # holding cost per unit leftover\n",
        "                 b=2.0           # backorder cost per unit short\n",
        "                ):\n",
        "        self.i_min = i_min\n",
        "        self.i_max = i_max\n",
        "        self.Q_max = Q_max\n",
        "        self.lambda_ = lambda_\n",
        "        self.beta = beta\n",
        "        # cost parameters\n",
        "        self.K = K\n",
        "        self.c = c\n",
        "        self.h = h\n",
        "        self.b = b\n",
        "\n",
        "        # Build the integer state space\n",
        "        self.state_space = np.arange(i_min, i_max + 1)  # e.g. [-5, -4, ..., 10]\n",
        "        self.n_states = len(self.state_space)\n",
        "        # Build the discrete action space\n",
        "        self.action_space = np.arange(Q_max + 1)  # e.g. [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "        # Precompute Poisson pmf up to some upper bound\n",
        "        # We pick something larger than i_max + Q_max - i_min to be safe\n",
        "        self.demand_max = max(0, i_max - i_min + Q_max + 5)\n",
        "        pmf_vals = [self.poisson_pmf(k, self.lambda_) for k in range(self.demand_max+1)]\n",
        "        self.demand_pmf = np.array(pmf_vals)\n",
        "\n",
        "        # Precompute transitions & expected immediate cost if we want to speed up\n",
        "        # (For large state spaces, this might be big. Here, let's do it for demonstration.)\n",
        "        self.trans_probs = {}\n",
        "        self.cost_cache = {}\n",
        "        for s_idx, i_val in enumerate(self.state_space):\n",
        "            for Q in self.action_space:\n",
        "                # Build distribution over next states\n",
        "                # i' = i_val + Q - d\n",
        "                # Probability that next state = j for each j in state_space\n",
        "                prob_vec = np.zeros(self.n_states)\n",
        "                exp_cost = 0.0\n",
        "                for d in range(self.demand_max + 1):\n",
        "                    prob_d = self.demand_pmf[d]\n",
        "                    i_next = i_val + Q - d\n",
        "                    # clamp i_next into [i_min, i_max]\n",
        "                    if i_next < self.i_min:\n",
        "                        i_next = self.i_min\n",
        "                    elif i_next > self.i_max:\n",
        "                        i_next = self.i_max\n",
        "                    next_idx = i_next - self.i_min  # index shift\n",
        "\n",
        "                    # immediate cost from realized demand d\n",
        "                    cost_d = self.one_period_cost(i_val, Q, d)\n",
        "                    exp_cost += prob_d * cost_d\n",
        "\n",
        "                    prob_vec[next_idx] += prob_d\n",
        "\n",
        "                self.trans_probs[(s_idx, Q)] = prob_vec\n",
        "                self.cost_cache[(s_idx, Q)] = exp_cost\n",
        "\n",
        "    def one_period_cost(self, i_val, Q, d):\n",
        "        \"\"\"Returns the cost in a single period, given state i_val, order Q, and realized demand d.\"\"\"\n",
        "        # After ordering Q, inventory becomes i_val + Q.\n",
        "        # Then demand d is subtracted: i' = i_val + Q - d.\n",
        "        # The realized cost:\n",
        "        #  1) fixed cost if Q>0\n",
        "        #  2) per-unit ordering cost c * Q\n",
        "        #  3) holding cost h * max(i', 0)\n",
        "        #  4) backorder cost b * max(-i', 0)\n",
        "        K_cost = self.K if Q > 0 else 0.0\n",
        "        c_cost = self.c * Q\n",
        "        i_prime = i_val + Q - d\n",
        "        hold_cost = self.h * max(i_prime, 0)\n",
        "        back_cost = self.b * max(-i_prime, 0)\n",
        "        return K_cost + c_cost + hold_cost + back_cost\n",
        "\n",
        "    @staticmethod\n",
        "    def poisson_pmf(k, lam):\n",
        "        \"\"\"Poisson(k; lambda)\"\"\"\n",
        "        from math import exp, factorial\n",
        "        if k < 0:\n",
        "            return 0.0\n",
        "        return lam**k * exp(-lam) / factorial(k)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 2. Value Iteration\n",
        "###############################################################################\n",
        "\n",
        "def solve_value_function(mdp, tol=1e-8, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Value iteration: for each state, we choose the action that minimizes\n",
        "    the expected one-period cost plus discounted future cost.\n",
        "\n",
        "    Returns: V (value function array) and Q_fct (cost-to-go for each state-action).\n",
        "    \"\"\"\n",
        "    nS = mdp.n_states\n",
        "    nA = len(mdp.action_space)\n",
        "    beta = mdp.beta\n",
        "\n",
        "    # Initialize V(s) = 0\n",
        "    V = np.zeros(nS)\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        V_old = V.copy()\n",
        "\n",
        "        # For each state s_idx, compute cost-to-go for each action\n",
        "        Q_fct = np.zeros((nS, nA))\n",
        "        for s_idx in range(nS):\n",
        "            for a_idx, Q in enumerate(mdp.action_space):\n",
        "                # immediate expected cost\n",
        "                cost = mdp.cost_cache[(s_idx, Q)]\n",
        "                # next-state distribution\n",
        "                prob_next = mdp.trans_probs[(s_idx, Q)]\n",
        "                # discounted expected future cost\n",
        "                future_cost = beta * np.dot(prob_next, V_old)\n",
        "                Q_fct[s_idx, a_idx] = cost + future_cost\n",
        "\n",
        "        # Next iteration's V(s) = min over a of Q_fct(s,a)\n",
        "        V = np.min(Q_fct, axis=1)\n",
        "\n",
        "        # Check convergence\n",
        "        if np.max(np.abs(V - V_old)) < tol:\n",
        "            break\n",
        "\n",
        "    # Return final V and Q_fct\n",
        "    return V, Q_fct\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 3. Choice Probabilities (Logit)\n",
        "###############################################################################\n",
        "\n",
        "def choice_probabilities(Q_fct, mu=1.0):\n",
        "    \"\"\"\n",
        "    Suppose the decision-maker chooses actions with logit probabilities\n",
        "    based on the *negative* of Q_fct (because Q_fct is cost-to-go,\n",
        "    and we assume the agent 'dislikes cost').\n",
        "\n",
        "    Probability that action a is chosen in state s ~\n",
        "        exp( -Q_fct[s,a] / mu ) / sum_{a'} exp( -Q_fct[s,a'] / mu )\n",
        "    \"\"\"\n",
        "    # We'll use \"negative cost\" as the \"utility\" in the logit exponent.\n",
        "    negQ = -Q_fct / mu\n",
        "    max_negQ = np.max(negQ, axis=1, keepdims=True)  # for numerical stability\n",
        "    exp_negQ = np.exp(negQ - max_negQ)\n",
        "    denom = np.sum(exp_negQ, axis=1, keepdims=True)\n",
        "    P = exp_negQ / denom\n",
        "    return P\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 4. Log-Likelihood Function\n",
        "###############################################################################\n",
        "\n",
        "def log_likelihood(theta, data, i_min, i_max, Q_max, lambda_, beta=0.95, mu=1.0):\n",
        "    \"\"\"\n",
        "    theta = [K, c, h, b] -> the cost parameters we want to estimate.\n",
        "\n",
        "    data = list of (i_obs, Q_obs) over time.\n",
        "\n",
        "    We'll:\n",
        "      1) Construct MDP with these parameters\n",
        "      2) Solve the DP for cost-to-go\n",
        "      3) Compute logit choice probabilities\n",
        "      4) Evaluate log-likelihood of observed (i_obs, Q_obs)\n",
        "    \"\"\"\n",
        "    K, h, b = theta\n",
        "\n",
        "    # Basic validity checks to keep params in a sensible range\n",
        "    if K < 0 or h < 0 or b < 0:\n",
        "        return 1e9  # big penalty\n",
        "\n",
        "    # 1) Build the MDP\n",
        "    mdp = InventoryBackorderMDP(\n",
        "        i_min=i_min, i_max=i_max, Q_max=Q_max,\n",
        "        lambda_=lambda_, beta=beta,\n",
        "        K=K, c=1, h=h, b=b\n",
        "    )\n",
        "\n",
        "    # 2) Solve DP\n",
        "    V, Q_fct = solve_value_function(mdp)\n",
        "\n",
        "    # 3) Compute choice probabilities\n",
        "    P_mat = choice_probabilities(Q_fct, mu=mu)  # shape (nS, nA)\n",
        "\n",
        "    # 4) Evaluate log-likelihood\n",
        "    ll = 0.0\n",
        "    state_offset = mdp.i_min  # so that index = i_obs - i_min\n",
        "    for (i_obs, Q_obs) in data:\n",
        "        s_idx = i_obs - state_offset\n",
        "        if s_idx < 0 or s_idx >= mdp.n_states:\n",
        "            # if data is out of range, either skip or penalize\n",
        "            ll += np.log(1e-12)\n",
        "        else:\n",
        "            Q_idx = Q_obs  # we matched action_space to [0..Q_max]\n",
        "            if Q_idx < 0 or Q_idx > Q_max:\n",
        "                ll += np.log(1e-12)\n",
        "            else:\n",
        "                # Probability that Q_obs was chosen in state i_obs\n",
        "                p = P_mat[s_idx, Q_idx]\n",
        "                ll += np.log(p + 1e-12)\n",
        "\n",
        "    return -ll  # negative log-likelihood\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 5. Data Simulation\n",
        "###############################################################################\n",
        "\n",
        "def simulate_data(mdp, T=1000, seed=42, mu=1.0):\n",
        "    \"\"\"\n",
        "    Simulate time-series data (i_t, Q_t) from the MDP,\n",
        "    assuming logit choice around the cost-to-go function.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # solve the DP\n",
        "    V, Q_fct = solve_value_function(mdp)\n",
        "    # get choice probabilities\n",
        "    P_mat = choice_probabilities(Q_fct, mu=mu)\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # Start from some initial inventory (e.g., 0)\n",
        "    i_t = 0\n",
        "    for t in range(T):\n",
        "        # find index of i_t\n",
        "        if i_t < mdp.i_min:\n",
        "            i_t = mdp.i_min\n",
        "        elif i_t > mdp.i_max:\n",
        "            i_t = mdp.i_max\n",
        "\n",
        "        s_idx = i_t - mdp.i_min\n",
        "        # pick Q according to P_mat[s_idx, :]\n",
        "        Q = np.random.choice(mdp.action_space, p=P_mat[s_idx])\n",
        "        data.append((i_t, Q))\n",
        "\n",
        "        # Realize demand\n",
        "        D = sample_poisson(mdp.lambda_)\n",
        "\n",
        "        # next inventory\n",
        "        i_next = i_t + Q - D\n",
        "        # allow it to go beyond i_min/i_max for simulation,\n",
        "        # but re-clamp if it goes beyond extremes\n",
        "        i_t = i_next\n",
        "\n",
        "    return data\n",
        "\n",
        "def sample_poisson(lam):\n",
        "    \"\"\"Simple Poisson sampler.\"\"\"\n",
        "    return np.random.poisson(lam)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 6. Parameter Estimation\n",
        "###############################################################################\n",
        "\n",
        "def estimate_parameters(\n",
        "        data,\n",
        "        i_min=-5,\n",
        "        i_max=10,\n",
        "        Q_max=5,\n",
        "        lambda_=2.0,\n",
        "        beta=0.95,\n",
        "        mu=1.0\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Estimate cost parameters [K, h, b] by MLE,\n",
        "    given the observed (i, Q) data, using logit errors.\n",
        "    \"\"\"\n",
        "    # objective for the optimizer\n",
        "    def objective(theta):\n",
        "        return log_likelihood(theta, data, i_min, i_max, Q_max, lambda_, beta=beta, mu=mu)\n",
        "\n",
        "    # initial guess\n",
        "    theta0 = np.array([3, 1, 2])  # [K, h, b]\n",
        "    bnds = [(0,None), (0,None), (0,None)]  # all >= 0\n",
        "\n",
        "    result = minimize(objective, theta0, method='L-BFGS-B', bounds=bnds)\n",
        "    return result\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 7. Demonstration (if run as script)\n",
        "###############################################################################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # \"True\" parameters for data generation\n",
        "    true_K = 5.0\n",
        "    true_c = 1\n",
        "    true_h = 0.5\n",
        "    true_b = 2.0\n",
        "    beta = 0.95\n",
        "    lambda_ = 4\n",
        "    mu = 0.5   # logit scale (smaller => more deterministic)\n",
        "\n",
        "    # Build MDP with the \"true\" parameters\n",
        "    mdp_true = InventoryBackorderMDP(\n",
        "        i_min=-5,\n",
        "        i_max=20,\n",
        "        Q_max=25,\n",
        "        lambda_=lambda_,\n",
        "        beta=beta,\n",
        "        K=true_K,\n",
        "        c=true_c,\n",
        "        h=true_h,\n",
        "        b=true_b\n",
        "    )\n",
        "\n",
        "    # Simulate data\n",
        "    data = simulate_data(mdp_true, T=2000, seed=123, mu=mu)\n",
        "\n",
        "    # Estimate parameters\n",
        "    x, y = zip(*data)\n",
        "\n",
        "    i_min = min(x)\n",
        "    i_max = max(x)\n",
        "    Q_max = max(y)\n",
        "\n",
        "\n",
        "    est_result = estimate_parameters(\n",
        "        data,\n",
        "        i_min,\n",
        "        i_max,\n",
        "        Q_max,\n",
        "        lambda_=lambda_,\n",
        "        beta=beta,\n",
        "        mu=mu\n",
        "    )\n",
        "\n",
        "    print(\"True        [K, h, b]:\", true_K, true_h, true_b)\n",
        "    print(\"Estimation Results:\")\n",
        "    print(\"  success:\", est_result.success)\n",
        "    print(\"  estimated [K, h, b]:\", est_result.x)\n",
        "    print(\"  negative log-likelihood:\", est_result.fun)\n",
        "    print(\"  message:\", est_result.message)\n"
      ]
    }
  ]
}